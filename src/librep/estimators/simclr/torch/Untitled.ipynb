{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441c4e98-74b4-494a-838a-7ec333497082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: be-great in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: scikit-learn>=1.1.1 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from be-great) (1.3.1)\n",
      "Requirement already satisfied: torch>=1.10.2 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from be-great) (2.1.0)\n",
      "Requirement already satisfied: datasets>=2.5.2 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from be-great) (2.14.5)\n",
      "Requirement already satisfied: transformers>=4.22.1 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from be-great) (4.34.0)\n",
      "Requirement already satisfied: accelerate>=0.20.1 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from be-great) (0.23.0)\n",
      "Requirement already satisfied: pandas>=1.4.4 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from be-great) (2.1.1)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from be-great) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.23.1 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from be-great) (1.25.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from accelerate>=0.20.1->be-great) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from accelerate>=0.20.1->be-great) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from accelerate>=0.20.1->be-great) (5.9.5)\n",
      "Requirement already satisfied: huggingface-hub in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from accelerate>=0.20.1->be-great) (0.17.3)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from datasets>=2.5.2->be-great) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from datasets>=2.5.2->be-great) (3.4.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/site-packages (from datasets>=2.5.2->be-great) (2.31.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from datasets>=2.5.2->be-great) (3.8.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from datasets>=2.5.2->be-great) (13.0.0)\n",
      "Requirement already satisfied: multiprocess in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from datasets>=2.5.2->be-great) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from datasets>=2.5.2->be-great) (2023.6.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from pandas>=1.4.4->be-great) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=1.4.4->be-great) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from pandas>=1.4.4->be-great) (2023.3.post1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from scikit-learn>=1.1.1->be-great) (1.11.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from scikit-learn>=1.1.1->be-great) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from scikit-learn>=1.1.1->be-great) (1.3.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (8.9.2.26)\n",
      "Requirement already satisfied: sympy in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (1.12)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (3.1.2)\n",
      "Requirement already satisfied: networkx in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (2.18.1)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (4.8.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (3.12.4)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from torch>=1.10.2->be-great) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.2->be-great) (12.2.140)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from transformers>=4.22.1->be-great) (2023.10.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from transformers>=4.22.1->be-great) (0.4.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from transformers>=4.22.1->be-great) (0.14.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.5.2->be-great) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.5.2->be-great) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.5.2->be-great) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.5.2->be-great) (1.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.5.2->be-great) (3.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.5.2->be-great) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.5.2->be-great) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.4->be-great) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.5.2->be-great) (2.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.5.2->be-great) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.5.2->be-great) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.10.2->be-great) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/amparo/unicamp_hyper/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages (from sympy->torch>=1.10.2->be-great) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install be-great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d388c070-0c36-4134-a1b4-f2849dd4842f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librep.datasets.arrow_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlibrep\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimclr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstandartized_balanced\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardizedBalancedDataset\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librep/__init__.py:18\u001b[0m\n\u001b[1;32m     12\u001b[0m     package \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[package_name]\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     14\u001b[0m         name: importlib\u001b[38;5;241m.\u001b[39mimport_module(package_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name)\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m loader, name, is_pkg \u001b[38;5;129;01min\u001b[39;00m pkgutil\u001b[38;5;241m.\u001b[39mwalk_packages(package\u001b[38;5;241m.\u001b[39m__path__)\n\u001b[1;32m     16\u001b[0m     }\n\u001b[0;32m---> 18\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m \u001b[43mimport_submodules\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librep/__init__.py:13\u001b[0m, in \u001b[0;36mimport_submodules\u001b[0;34m(package_name)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Import all submodules of a module, recursively\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m:param package_name: Package name\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m:type package_name: str\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m:rtype: dict[types.ModuleType]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m package \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[package_name]\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     14\u001b[0m     name: importlib\u001b[38;5;241m.\u001b[39mimport_module(package_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loader, name, is_pkg \u001b[38;5;129;01min\u001b[39;00m pkgutil\u001b[38;5;241m.\u001b[39mwalk_packages(package\u001b[38;5;241m.\u001b[39m__path__)\n\u001b[1;32m     16\u001b[0m }\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librep/__init__.py:14\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Import all submodules of a module, recursively\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m:param package_name: Package name\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m:type package_name: str\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m:rtype: dict[types.ModuleType]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m package \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[package_name]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m---> 14\u001b[0m     name: \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpackage_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loader, name, is_pkg \u001b[38;5;129;01min\u001b[39;00m pkgutil\u001b[38;5;241m.\u001b[39mwalk_packages(package\u001b[38;5;241m.\u001b[39m__path__)\n\u001b[1;32m     16\u001b[0m }\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'librep.datasets.arrow_dataset'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from librep.estimators.simclr.torch.standartized_balanced import StandardizedBalancedDataset\n",
    "import os,torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def get_data(dataset_name,sensors,normalize_data):    \n",
    "    working_directory=f\"result/{dataset_name}/\"\n",
    "    data_folder = f\"../../../../../../experiment_executor/data/standartized_balanced/{dataset_name}/\"\n",
    "    dataset = StandardizedBalancedDataset(data_folder, sensors=sensors)\n",
    "    X_train, y_train,X_test, y_test,X_val, y_val = dataset.get_all_data(normalize_data=normalize_data, resize_data=False)\n",
    "    return X_train, y_train,X_test, y_test,X_val, y_val\n",
    "        #print(f\"shape: X_train {X_train.shape} --- X_test {X_test.shape} --- X_test {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "006b53ee-8273-44b6-b62a-779d714ac526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a29298e-0867-43bc-b244-195620ed4873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='16125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   57/16125 02:02 < 9:55:16, 0.45 it/s, Epoch 0.09/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m fetch_california_housing(as_frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mframe\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m GReaT(llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistilgpt2\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m synthetic_data \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39msample(n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/be_great/great.py:175\u001b[0m, in \u001b[0;36mGReaT.fit\u001b[0;34m(self, data, column_names, conditional_col, resume_from_checkpoint)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m    174\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 175\u001b[0m \u001b[43mgreat_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m great_trainer\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1591\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1892\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1892\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1895\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1896\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1898\u001b[0m ):\n\u001b[1;32m   1899\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1900\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2787\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2786\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2787\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2789\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/accelerator.py:1985\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1985\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from be_great import GReaT\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data = fetch_california_housing(as_frame=True).frame\n",
    "\n",
    "model = GReaT(llm='distilgpt2', batch_size=32, epochs=25)\n",
    "model.fit(data)\n",
    "synthetic_data = model.sample(n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4117fef-214d-4755-bfbe-01c0aca9a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981bf94f-e7ea-49d3-91cd-2829f8f17660",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d961a7a-daf2-429c-a6f2-e62118665965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
