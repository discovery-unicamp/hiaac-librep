{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb03c8ae-1724-46e4-9abf-ea79705024f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/usr/local/lib/python3.8/dist-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/usr/local/lib/python3.8/dist-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/usr/local/lib/python3.8/dist-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "2023-09-13 13:26:25.564164: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 13:26:25.694865: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-09-13 13:26:26.221804: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-09-13 13:26:26.221857: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-09-13 13:26:26.221863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  \n",
    "from librep.base.estimator import Estimator\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from standartized_balanced import StandardizedBalancedDataset\n",
    "import os,torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_data(dataset_name,sensors,normalize_data):    \n",
    "    working_directory=f\"result/{dataset_name}/\"\n",
    "    data_folder = f\"../../data/data/standartized_balanced/{dataset_name}/\"\n",
    "    dataset = StandardizedBalancedDataset(data_folder, sensors=sensors)\n",
    "    X_train, y_train,X_test, y_test,X_val, y_val = dataset.get_all_data(normalize_data=normalize_data, resize_data=False)\n",
    "    return X_train, y_train,X_test, y_test,X_val, y_val\n",
    "        #print(f\"shape: X_train {X_train.shape} --- X_test {X_test.shape} --- X_test {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "037077a6-c130-43b3-88dd-dfc6700068cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train,X_test, y_test,X_val, y_val=get_data(\"MotionSense\",['accel','gyro'],False)\n",
    "input_shape=X_train[0].shape\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2f455d-3102-4df9-beb8-2d885ec8c146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 5.450\n",
      "epoch: 2 loss: 5.401\n",
      "epoch: 3 loss: 5.295\n",
      "epoch: 4 loss: 5.157\n",
      "epoch: 5 loss: 5.018\n",
      "epoch: 6 loss: 4.976\n",
      "epoch: 7 loss: 4.936\n",
      "epoch: 8 loss: 4.865\n",
      "epoch: 9 loss: 4.829\n",
      "epoch: 10 loss: 4.773\n",
      "epoch: 11 loss: 4.762\n",
      "epoch: 12 loss: 4.752\n",
      "epoch: 13 loss: 4.731\n",
      "epoch: 14 loss: 4.715\n",
      "epoch: 15 loss: 4.706\n",
      "epoch: 16 loss: 4.665\n",
      "epoch: 17 loss: 4.634\n",
      "epoch: 18 loss: 4.639\n",
      "epoch: 19 loss: 4.608\n",
      "epoch: 20 loss: 4.595\n",
      "epoch: 21 loss: 4.589\n",
      "epoch: 22 loss: 4.560\n",
      "epoch: 23 loss: 4.570\n",
      "epoch: 24 loss: 4.555\n",
      "epoch: 25 loss: 4.546\n",
      "epoch: 26 loss: 4.536\n",
      "epoch: 27 loss: 4.532\n",
      "epoch: 28 loss: 4.530\n",
      "epoch: 29 loss: 4.538\n",
      "epoch: 30 loss: 4.540\n",
      "epoch: 31 loss: 4.511\n",
      "epoch: 32 loss: 4.506\n",
      "epoch: 33 loss: 4.495\n",
      "epoch: 34 loss: 4.483\n",
      "epoch: 35 loss: 4.490\n",
      "epoch: 36 loss: 4.484\n",
      "epoch: 37 loss: 4.473\n",
      "epoch: 38 loss: 4.468\n",
      "epoch: 39 loss: 4.471\n",
      "epoch: 40 loss: 4.478\n",
      "epoch: 41 loss: 4.455\n",
      "epoch: 42 loss: 4.460\n",
      "epoch: 43 loss: 4.464\n",
      "epoch: 44 loss: 4.453\n",
      "epoch: 45 loss: 4.450\n",
      "epoch: 46 loss: 4.446\n",
      "epoch: 47 loss: 4.443\n",
      "epoch: 48 loss: 4.446\n",
      "epoch: 49 loss: 4.443\n",
      "epoch: 50 loss: 4.428\n",
      "epoch: 51 loss: 4.427\n",
      "epoch: 52 loss: 4.418\n",
      "epoch: 53 loss: 4.429\n",
      "epoch: 54 loss: 4.441\n",
      "epoch: 55 loss: 4.421\n",
      "epoch: 56 loss: 4.405\n",
      "epoch: 57 loss: 4.420\n",
      "epoch: 58 loss: 4.428\n",
      "epoch: 59 loss: 4.416\n",
      "epoch: 60 loss: 4.403\n",
      "epoch: 61 loss: 4.412\n",
      "epoch: 62 loss: 4.416\n",
      "epoch: 63 loss: 4.409\n",
      "epoch: 64 loss: 4.409\n",
      "epoch: 65 loss: 4.394\n",
      "epoch: 66 loss: 4.395\n",
      "epoch: 67 loss: 4.405\n",
      "epoch: 68 loss: 4.388\n",
      "epoch: 69 loss: 4.399\n",
      "epoch: 70 loss: 4.388\n",
      "epoch: 71 loss: 4.386\n",
      "epoch: 72 loss: 4.387\n",
      "epoch: 73 loss: 4.378\n",
      "epoch: 74 loss: 4.376\n",
      "epoch: 75 loss: 4.382\n",
      "epoch: 76 loss: 4.380\n",
      "epoch: 77 loss: 4.370\n",
      "epoch: 78 loss: 4.375\n",
      "epoch: 79 loss: 4.364\n",
      "epoch: 80 loss: 4.369\n",
      "epoch: 81 loss: 4.382\n",
      "epoch: 82 loss: 4.371\n",
      "epoch: 83 loss: 4.367\n",
      "epoch: 84 loss: 4.366\n",
      "epoch: 85 loss: 4.380\n",
      "epoch: 86 loss: 4.368\n",
      "epoch: 87 loss: 4.367\n",
      "epoch: 88 loss: 4.371\n",
      "epoch: 89 loss: 4.372\n",
      "Early stopping after 89 epochs with no improvement.\n",
      "(712, 60, 6) (712, 6)\n",
      "Epoch [1/50] - Loss: 0.799500935198216\n",
      "Val Accuracy: 0.7640\n",
      "Epoch [2/50] - Loss: 0.47131727635860443\n",
      "Val Accuracy: 0.7683\n",
      "Epoch [3/50] - Loss: 0.40469656851184505\n",
      "Val Accuracy: 0.8624\n",
      "Epoch [4/50] - Loss: 0.316236236959361\n",
      "Val Accuracy: 0.8708\n",
      "Epoch [5/50] - Loss: 0.28422512716791604\n",
      "Val Accuracy: 0.8666\n",
      "Epoch [6/50] - Loss: 0.26271772953901396\n",
      "Val Accuracy: 0.8904\n",
      "Epoch [7/50] - Loss: 0.20860638423414712\n",
      "Val Accuracy: 0.8933\n",
      "Epoch [8/50] - Loss: 0.17929815136817065\n",
      "Val Accuracy: 0.8947\n",
      "Epoch [9/50] - Loss: 0.14788232943608184\n",
      "Val Accuracy: 0.9143\n",
      "Epoch [10/50] - Loss: 0.15499253448601183\n",
      "Val Accuracy: 0.8904\n",
      "Epoch [11/50] - Loss: 0.12416988482510441\n",
      "Val Accuracy: 0.9115\n",
      "Epoch [12/50] - Loss: 0.0902919374626088\n",
      "Val Accuracy: 0.9073\n",
      "Epoch [13/50] - Loss: 0.07757583895457511\n",
      "Val Accuracy: 0.9143\n",
      "Epoch [14/50] - Loss: 0.07956589310000954\n",
      "Val Accuracy: 0.8904\n",
      "Epoch [15/50] - Loss: 0.09648526871179262\n",
      "Val Accuracy: 0.9242\n",
      "Epoch [16/50] - Loss: 0.059802784177663035\n",
      "Val Accuracy: 0.9171\n",
      "Epoch [17/50] - Loss: 0.05601135764030342\n",
      "Val Accuracy: 0.9087\n",
      "Epoch [18/50] - Loss: 0.04902979433065636\n",
      "Val Accuracy: 0.9031\n",
      "Epoch [19/50] - Loss: 0.08150882038204105\n",
      "Val Accuracy: 0.9143\n",
      "Epoch [20/50] - Loss: 0.04357291139227997\n",
      "Val Accuracy: 0.9242\n",
      "Epoch [21/50] - Loss: 0.04794845238505873\n",
      "Val Accuracy: 0.9171\n",
      "Epoch [22/50] - Loss: 0.05237763226189222\n",
      "Val Accuracy: 0.9157\n",
      "Epoch [23/50] - Loss: 0.03122019064625767\n",
      "Val Accuracy: 0.9298\n",
      "Epoch [24/50] - Loss: 0.0685510174191447\n",
      "Val Accuracy: 0.9242\n",
      "Epoch [25/50] - Loss: 0.026961949784727244\n",
      "Val Accuracy: 0.9228\n",
      "Epoch [26/50] - Loss: 0.05607605515161707\n",
      "Val Accuracy: 0.9242\n",
      "Epoch [27/50] - Loss: 0.026269692777174662\n",
      "Val Accuracy: 0.9284\n",
      "Epoch [28/50] - Loss: 0.01847723082044447\n",
      "Val Accuracy: 0.9157\n",
      "Epoch [29/50] - Loss: 0.010832741526213836\n",
      "Val Accuracy: 0.9326\n",
      "Epoch [30/50] - Loss: 0.0222025379798345\n",
      "Val Accuracy: 0.9256\n",
      "Epoch [31/50] - Loss: 0.030764751771191565\n",
      "Val Accuracy: 0.9199\n",
      "Epoch [32/50] - Loss: 0.03955502517170174\n",
      "Val Accuracy: 0.9129\n",
      "Epoch [33/50] - Loss: 0.030095729331049044\n",
      "Val Accuracy: 0.9199\n",
      "Epoch [34/50] - Loss: 0.022488272130349388\n",
      "Val Accuracy: 0.9143\n",
      "Epoch [35/50] - Loss: 0.022615510511559987\n",
      "Val Accuracy: 0.9199\n",
      "Epoch [36/50] - Loss: 0.026876295563729554\n",
      "Val Accuracy: 0.9298\n",
      "Epoch [37/50] - Loss: 0.026621520196743638\n",
      "Val Accuracy: 0.9270\n",
      "Epoch [38/50] - Loss: 0.021510909352267783\n",
      "Val Accuracy: 0.9171\n",
      "Epoch [39/50] - Loss: 0.08469129015078108\n",
      "Val Accuracy: 0.8904\n",
      "Epoch [40/50] - Loss: 0.037762504595520205\n",
      "Val Accuracy: 0.9059\n",
      "Epoch [41/50] - Loss: 0.024077410037217927\n",
      "Val Accuracy: 0.9213\n",
      "Epoch [42/50] - Loss: 0.01912173292020158\n",
      "Val Accuracy: 0.9115\n",
      "Epoch [43/50] - Loss: 0.016149166053039378\n",
      "Val Accuracy: 0.8975\n",
      "Epoch [44/50] - Loss: 0.02482875012519594\n",
      "Val Accuracy: 0.9143\n",
      "Epoch [45/50] - Loss: 0.05089525789832366\n",
      "Val Accuracy: 0.9143\n",
      "Epoch [46/50] - Loss: 0.017887564165239078\n",
      "Val Accuracy: 0.9129\n",
      "Epoch [47/50] - Loss: 0.010392560133235687\n",
      "Val Accuracy: 0.9284\n",
      "Epoch [48/50] - Loss: 0.012628683675746983\n",
      "Val Accuracy: 0.9185\n",
      "Epoch [49/50] - Loss: 0.006254150013876242\n",
      "Val Accuracy: 0.9143\n",
      "Epoch [50/50] - Loss: 0.00949820804052752\n",
      "Val Accuracy: 0.9213\n",
      "Training finished.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<simclr_estimator.Simclr_Estimator at 0x7f3ece1908b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from simclr_estimator import Simclr_Estimator\n",
    "\n",
    "batch_size_head = 256\n",
    "decay_steps_head = 1000\n",
    "epochs_head = 300\n",
    "temperature_head = 0.5\n",
    "input_shape=X_train[0].shape\n",
    "\n",
    "transform_funcs=['noise_vectorized','noise_vectorized']\n",
    "est=Simclr_Estimator(sequence_length=60, input_size=6,trained_simclr_model=None,input_shape=input_shape,\n",
    "                batch_size_head=batch_size_head,transform_funcs=transform_funcs,\n",
    "              temperature_head=temperature_head,epochs_head=epochs_head,\n",
    "                 save_model=False,verbose=1,total_epochs=50,\n",
    "                 batch_size=32,lr=0.001,classificator='full')\n",
    "\n",
    "est.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd870c1-1963-4f21-882e-e4f3748926d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions = est.predict(X_test)\n",
    "true_classes = np.argmax(y_test, axis=1)\n",
    "#print(predictions)\n",
    "for a in zip(predictions,true_classes):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25384e30-6ec7-4872-8777-2f68fd23ed58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
